= Query Functions

### getInstalledQueries(fmt: str = "py") -> [dict, json, pd.DataFrame]:

### runInstalledQuery(queryName: str, params: [str, dict] = None, timeout: int = None,sizeLimit: int = None, usePost: bool = False) -> list:
Runs an installed query.


The query must be already created and installed in the graph.

Use ``getEndpoints(dynamic=True)`` or GraphStudio to find out the generated endpoint URL of
the query, but only the query name needs to be specified here.


#### Parameters:

queryName:
The name of the query to be executed.

params:
Query parameters. A string of param1=value1&param2=value2 format or a dictionary.

timeout:
Maximum duration for successful query execution (in milliseconds).

See: https://docs.tigergraph.com/dev/restpp-api/intro#gsql-query-timeout

sizeLimit:
Maximum size of response (in bytes).

See: https://docs.tigergraph.com/dev/restpp-api/intro#response-size

usePost:
The RESTPP accepts a maximum URL length of 8192 characters. Use POST if params cause

you to exceed this limit.


#### Returns:

The output of the query, a list of output elements (vertex sets, edge sets, variables,
accumulators, etc.


Endpoint:
GET /query/{graph_name}/{query_name}
Documentation:
https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#run-an-installed-query-get


Endpoint:
POST /query/{graph_name}/{query_name}
Documentation:
https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#run-an-installed-query-post


TODO Specify replica: GSQL-REPLICA
TODO Specify thread limit: GSQL-THREAD-LIMIT
TODO Detached mode

### runInterpretedQuery(queryText: str, params: [str, dict] = None) -> list:
Runs an interpreted query.


Use ``@graphname@`` in the ``FOR GRAPH`` clause to avoid hard-coding it; it will be replaced
by the actual graph name.


#### Parameters:

queryText:
The text of the GSQL query:
You must provide the query text in this format:
INTERPRET QUERY (<params>) FOR GRAPH <graph_name> {
<statements>
}
params:
A string of param1=value1&param2=value2 format or a dictionary.


Endpoint:
POST /gsqlserver/interpreted_query
Documentation:
https://docs.tigergraph.com/dev/restpp-api/built-in-endpoints#run-an-interpreted-query


### parseQueryOutput(output: list, graphOnly: bool = True) -> dict:
Parses query output and separates vertex and edge data (and optionally other output) for
easier use.


#### Parameters:

output:
The data structure returned by `runInstalledQuery()` or `runInterpretedQuery()`.

graphOnly:
Should output be restricted to vertices and edges (True, default) or should any
other output (e.g. values of variables or accumulators, or plain text printed) be

captured as well.


#### Returns:

A dictionary with two (or three) keys: "vertices", "edges" and optionally "output".

First two refer to another dictionary containing keys for each vertex and edge types
found, and the instances of those vertex and edge types. "output" is a list of

dictionaries containing the key/value pairs of any other output.


The JSON output from a query can contain a mixture of results: vertex sets (the output of a
SELECT statement), edge sets (e.g. collected in a global accumulator), printout of

global and local variables and accumulators, including complex types (LIST, MAP, etc.).

The type of the various output entries is not explicit, you need to inspect the content
to find out what it is actually.

This function "cleans" this output, separating and collecting vertices and edges in an easy
to access way. It can also collect other output or ignore it.

The output of this function can be used e.g. with the `vertexSetToDataFrame()` and

`edgeSetToDataFrame()` functions or (after some transformation) to pass a subgraph to a
visualisation component.


### getStatistics(seconds: int = 10, segments: int = 10) -> dict:
Retrieves real-time query performance statistics over the given time period.


#### Parameters:

seconds:
The duration of statistic collection period (the last n seconds before the function
call).

segments:
The number of segments of the latency distribution (shown in results as
LatencyPercentile). By default, segments is 10, meaning the percentile range 0-100%

will be divided into ten equal segments: 0%-10%, 11%-20%, etc.

Segments must be [1, 100].


Endpoint:
GET /statistics/{graph_name}
Documentation:
https://docs.tigergraph.com/tigergraph-server/current/api/built-in-endpoints#_show_query_performance


