= pyTigerGraph GDS Metrics

:stem: latexmath

Utility for gathering metrics for GNN predictions.

== Accuracy

Accuracy = sum(preds == labels) / len(labels)

Usage:

* Call the update function to add predictions and labels.
* Get accuracy score at any point by accessing the value proporty.

=== update()
`update(preds: ndarray, labels: ndarray) -> None`

Add predictions and labels to be compared.

[discrete]
==== **Parameters:**
preds (ndarray): 
Array of predicted labels.
labels (ndarray): 
Array of true labels.


=== value()
`value() -> float`

Get accuracy score.
[discrete]
==== **Returns:**
Accuracy score (float).


== Recall

Recall = stem:[rac{\sum(preds * labels)}{\sum(labels)}]

Usage:

* Call the update function to add predictions and labels.
* Get recall score at any point by accessing the value proporty.

=== update()
`update(preds: ndarray, labels: ndarray) -> None`

Add predictions and labels to be compared.

[discrete]
==== **Parameters:**
preds (ndarray): 
Array of predicted labels.
labels (ndarray): 
Array of true labels.


=== value()
`value() -> float`

Get recall score.
[discrete]
==== **Returns:**
Recall score (float).


== Precision

Precision = stem:[rac{\sum(preds * labels)}{\sum(preds)}]

Usage:

* Call the update function to add predictions and labels.
* Get precision score at any point by accessing the value proporty.

=== update()
`update(preds: ndarray, labels: ndarray) -> None`

Add predictions and labels to be compared.

[discrete]
==== **Parameters:**
preds (ndarray): 
Array of predicted labels.
labels (ndarray): 
Array of true labels.


=== value()
`value() -> float`

Get precision score.
[discrete]
==== **Returns:**
Precision score (float).


