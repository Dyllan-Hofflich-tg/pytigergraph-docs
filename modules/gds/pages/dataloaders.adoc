= Data Loaders

:description: Data loader classes in the pyTigerGraph GDS module. 

Data loaders are classes in the pyTigerGraph Graph Data Science (GDS) module. 
You can define an instance of each data loader class through a link:https://docs.tigergraph.com/pytigergraph/current/gds/factory-functions[factory function].

Requires `querywriters` user permissions for full functionality. 

== NeighborLoader


=== \__init__()
`__init__(graph: TigerGraphConnection, v_in_feats: Union[list, dict] = None, v_out_labels: Union[list, dict] = None, v_extra_feats: Union[list, dict] = None, e_in_feats: Union[list, dict] = None, e_out_labels: Union[list, dict] = None, e_extra_feats: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, num_neighbors: int = 10, num_hops: int = 2, shuffle: bool = False, filter_by: str = None, output_format: str = "PyG", add_self_loop: bool = False, loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) -> None`

A data loader that performs neighbor sampling.
See more details about the specific sampling method in 
link:https://arxiv.org/abs/1706.02216[Inductive Representation Learning on Large Graphs].

It first chooses `batch_size` number of vertices as seeds,
then picks `num_neighbors` number of neighbors of each seed at random,
then `num_neighbors` neighbors of each neighbor, and repeat for `num_hops`.
This generates one subgraph. As you loop through this data loader, every
vertex will at some point be chosen as a seed and you will get the subgraph
expanded from the seed. If you want to limit seeds to certain vertices, the boolean
attribute provided to `filter_by` will be used to indicate which vertices can be
included as seeds.


There are two ways to use the data loader:

* It can be used as an iterable, which means you can loop through
it to get every batch of data. If you load all data at once (`num_batches=1`),
there will be only one batch (of all the data) in the iterator.
* You can access the `data` property of the class directly. If there is
only one batch of data to load, it will give you the batch directly instead
of an iterator, which might make more sense in that case. If there are
multiple batches of data to load, it will return the loader itself.

See https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_neighborloader.ipynb[the ML Workbench tutorial notebook]
for examples.


=== data
`data -> Any`

Return the last data read from the queue.


== EdgeLoader


=== \__init__()
`__init__(graph: TigerGraphConnection, attributes: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, shuffle: bool = False, filter_by: str = None, output_format: str = "dataframe", loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) -> None`

Data loader that pulls batches of edges from database.

It divides edges into `num_batches` and returns each batch separately.
The boolean attribute provided to `filter_by` indicates which edges are included.
If you need random batches, set `shuffle` to True.

NOTE: When you initialize the loader on a graph for the first time,
the initialization might take a minute as it installs the corresponding
query to the database. However, the query installation only
needs to be done once, so it will take no time when you initialize the loader
on the same graph again.

There are two ways to use the data loader.

* It can be used as an iterable, which means you can loop through
it to get every batch of data. If you load all edges at once (`num_batches=1`),
there will be only one batch (of all the edges) in the iterator.
* You can access the `data` property of the class directly. If there is
only one batch of data to load, it will give you the batch directly instead
of an iterator, which might make more sense in that case. If there are
multiple batches of data to load, it will return the loader again.

See https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_edgeloader.ipynb[the ML Workbench edge loader tutorial notebook]
for examples.


=== data
`data -> Any`

Return the last data read from the queue.


== VertexLoader


=== \__init__()
`__init__(graph: TigerGraphConnection, attributes: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, shuffle: bool = False, filter_by: str = None, output_format: str = "dataframe", loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) -> None`

Data loader that pulls batches of vertices from database.

It divides vertices into `num_batches` and returns each batch separately.
The boolean attribute provided to `filter_by` indicates which vertices are included.
If you need random batches, set `shuffle` to True.

NOTE: When you initialize the loader on a graph for the first time,
the initialization might take a minute as it installs the corresponding
query to the database. However, the query installation only
needs to be done once, so it will take no time when you initialize the loader
on the same graph again.

There are two ways to use the data loader:

* First, it can be used as an iterable, which means you can loop through
it to get every batch of data. If you load all vertices at once (`num_batches=1`),
there will be only one batch (of all the vertices) in the iterator.
* Second, you can access the `data` property of the class directly. If there is
only one batch of data to load, it will give you the batch directly instead
of an iterator, which might make more sense in that case. If there are
multiple batches of data to load, it will return the loader again.

See https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_vertexloader.ipynb[the ML Workbench tutorial notebook]
for examples.


=== data
`data -> Any`

Return the last data read from the queue.


== GraphLoader


=== \__init__()
`__init__(graph: TigerGraphConnection, v_in_feats: Union[list, dict] = None, v_out_labels: Union[list, dict] = None, v_extra_feats: Union[list, dict] = None, e_in_feats: Union[list, dict] = None, e_out_labels: Union[list, dict] = None, e_extra_feats: Union[list, dict] = None, batch_size: int = None, num_batches: int = 1, shuffle: bool = False, filter_by: str = None, output_format: str = "PyG", add_self_loop: bool = False, loader_id: str = None, buffer_size: int = 4, kafka_address: str = None, kafka_max_msg_size: int = 104857600, kafka_num_partitions: int = 1, kafka_replica_factor: int = 1, kafka_retention_ms: int = 60000, kafka_auto_del_topic: bool = True, kafka_address_consumer: str = None, kafka_address_producer: str = None, timeout: int = 300000) -> None`

Data loader that pulls batches of vertices and edges from database.

Different from NeighborLoader which produces connected subgraphs, this loader
generates (random) batches of edges and vertices attached to those edges.

There are two ways to use the data loader:

* It can be used as an iterable, which means you can loop through
it to get every batch of data. If you load all data at once (`num_batches=1`),
there will be only one batch (of all the data) in the iterator.
* You can access the `data` property of the class directly. If there is
only one batch of data to load, it will give you the batch directly instead
of an iterator, which might make more sense in that case. If there are
multiple batches of data to load, it will return the loader itself.

See https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/1.0/tutorials/basics/3_graphloader.ipynb[the ML Workbench tutorial notebook for graph loaders]
for examples.


=== data
`data -> Any`

Return the last data read from the queue.


